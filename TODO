☐	Apply->Predict/Test, or something more ML-like
☐	Perhaps writing_lock not needed? Afterall, an instance is only managed by a single node/thread at a time
☐	Define relations as constants like E̅
☐	enumAccessibles(set) is not needed?!
☐	what to do with nans? Perhaps a NaN means that a world must be ignored??? In that case, one could easily design features that ignore small worlds!
☐	getCanonicalFeature->getFeature
☐	create meta-feature that gives features a name.
☐	length(unique(x)) == 1 -> allequal(x) in Julia 1.8

################################################################################
☐	CODE: Check type-stability with code_warntype!
	- https://docs.julialang.org/en/v1/devdocs/reflection/#Intermediate-and-compiled-representations
	- https://www.johnmyleswhite.com/notebook/2013/12/06/writing-type-stable-code-in-julia/ e.g. type-stable slicing with JuliennedArrays ( from https://discourse.julialang.org/t/way-to-slice-an-array-of-unknown-number-of-dimensions/27246 ), EllipsisNotation https://github.com/ChrisRackauckas/EllipsisNotation.jl. Use \@code_warntype as in https://discourse.julialang.org/t/why-selectdim-is-type-instable/25271/2 to double check each function https://nextjournal.com/jbieler/adding-static-type-checking-to-julia-in-100-lines-of-code/
☐	CODE: Add test suite for each piece of code
☐	CODE: try improving performances with @inbounds. @propagate_inbounds (and @boundscheck): "In general, bounds-check removal should be the last optimization you make after ensuring everything else works, is well-tested, and follows the usual performance tips." https://stackoverflow.com/questions/38901275/inbounds-propagation-rules-in-julia?utm_medium=organic&utm_source=google_rich_qa&utm_campaign=google_rich_qa
☐	CODE: adhere to style https://github.com/invenia/BlueStyle
☐	CODE: Add proper comments, docs and authors
☐	CODE: Fix naming style (e.g. variables/features/attributes, etc. Order of struct's members)
☐	CODE: Custom pretty printing, instead of display_. Figure out print/show/display See https://docs.julialang.org/en/v1/manual/types/#man-custom-pretty-printing https://schurkus.com/2018/01/05/julia-print-show-display-dump-what-to-override-what-to-use/
☐	CODE: Keep this: throw, error(), @error -> throw_n_log()
☐	CODE: Improve output/logging
☐	CODE: DTree->ModalTree; DForest->ModalForest.
################################################################################
☐	MODEL: Bagging, XGBoost https://towardsdatascience.com/ensemble-learning-bagging-and-boosting-explained-in-3-minutes-2e6d2240ae21
☐	MODEL: Model may not have an answer? problem with argmax when testing (e.g. RF), especially on unbalanced datasets
☐	MODEL: attach more info to the models: algorithm used, full namedtuple of training arguments, pre-process pipeline. remove cm and oob_error from random forest? OR also attach a structure that measures training performances. See what other libraries do
☐	MODEL: add info gain of the split to each internal node, purity to each node/leaf
☐	MODEL: Add tree parser and convenience methods for tree editing.
☐	MODEL: introduce post pruning (improve pre-pruning/post-pruning against a dataset and introduce validation/test set distinction)
################################################################################
✔	SCANNER.JL: different frames with different ontologies: @done (22-02-05 23:59)
✔	SCANNER.JL: Train with less stringent parameters, and post-prune @done (22-02-05 23:59)
################################################################################
☐	IntervalFWD could have thresholds with different type from the origin dataset
☐	MODALLOGIC.JL: Define relations as constants like IA_E̅Ea nd IA_Ei
☐	MODALLOGIC.JL: OPTIMIZE: add enumAccReprAggr for relationGlob, and for all worldtypes and relations
☐	? MODALLOGIC.JL: also remove enumAccRepr.
☐	? MODALLOGIC.JL: Remove n_relations()?
☐	MODALLOGIC.JL: OPTIMIZE: enumAccessibles and others for sets. But wait, maybe they are not that useful nor needed?
☐	MODALLOGIC.JL computePropositionalThreshold, computeModalThreshold, test_decision seem to do similar things. Maybe uniform their style and naming
☐	MODALLOGIC.JL Add the generalized solution for union of relations: _UnionOfRelations and its WExtremaModal, WExtrema, WExtremeModal, WExtreme, enumAcc, enumAccRepr. _UnionOfRelations{typeof((RelationId,))} _UnionOfRelations{typeof((RelationId,))} Tuple{_RelationId} (so you can rewrite RCC5 from RCC8 relations and RCC8 from IA, maybe it's cleaner in some cases?)
☐	MODALLOGIC.JL: DIMENSIONAL/MODAL difference, An ontology interpreted over an N-dimensional domain gives rise to a Kripke model/frame, but one can *generalize for a Kripke model/frame in graph form*.
	abstract type AbstractKripkeFrame end
	Generic Kripke frame: worlds & relations
	struct KripkeFrame{T} <: AbstractKripkeFrame{T}
☐	MODALLOGIC.JL Synthesis of SoleLogic module
☐	MODALLOGIC.JL Add TESTs for enumAcc optimizations
################################################################################
☐	DATA: _split!: enable learning in implicit form (allow training directly on InterpretedModalDataset) and study parallelization.
☐	DATA: Create class for labeled datasets, and remove slice_mf_dataset.
☐	? DATA: test round_dataset_to_datatype/mapArrayToDataType in multiframe version
☐	DATA: Clean dataset creation pipeline
☐	DATA: add filters (e.g., derivatives, Edge detection, which is spatial https://juliahub.com/docs/ImageEdgeDetection/5h14T/0.1.0/#ImageEdgeDetection.jl-Documentation)!
☐	DATA: give names to features (e.g. create meta-feature that give features a name.)
☐	DATA: feat modal dataset and matricial dataset may have different types. use Base.return_types and promote_type to infer them? Attach to each feature the return type?
☐	DATA: Instances with different channel size: find implementation of multi-dimensional array where one can specify that along one axis subArrays have non-uniform size?! And highlight difference between channel_size and max_channel_size ArraysOfVector https://juliaarrays.github.io/ArraysOfArrays.jl/stable/ https://github.com/JuliaArrays/BlockArrays.jl
################################################################################
☐	INTERFACE: Support for learning on dataframes
☐	INTERFACE: Add a symbol parameter for selecting a trade-off between time and space
☐	INTERFACE: build_random_forest calls Decision Forest with ...
☐	INTERFACE: build_forest Add (Val{Bool}?) oob_error parameter (note that oob computation is expensive)
☐	INTERFACE: Restore optimizations for edge cases (remember optimize_tree_parameters!?)
################################################################################



☐	what to do with nans? Perhaps a NaN means that a world must be ignored??? In that case, one could easily design features that ignore small worlds!


☐	Generalize World as a tuple of parameters ( https://stackoverflow.com/questions/40160120/generic-constructors-for-subtypes-of-an-abstract-type )
☐	Generalize to beam-search and then beam-search-n?

☐	Check whether CatWalk.jl can help runtime dispatch look-up time

☐	OPTIMIZE: yield said to be fast with Continuables.jl. https://schlichtanders.github.io/Continuables.jl/dev/

☐	Use streaming algorithms for the computation of the variance and of the entropy!!! Actually entropy only uses O(n_classes) memory, while variance is more problematic https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance

☐	In general, remove all gamma infrastructure. But maybe in the future it will make useful code for an edge case? In that case, make sure it can't be cache-efficiently parallelized. https://github.com/JuliaArrays/TiledIteration.jl
☐	Decision Tree Lookahead (e.g. two levels of decisions in one)
☐	CHECKS: Add checks for enumAcc optimizations: compute one without optimizations and one with optimizations and check that they are equivalent
☐	OPTIMIZE: Try running with: --compile=min -O0, and then with -O3
☐	OPTIMIZE: Test whether it's better to use that thresholds[:,i_instance] = map(aggr->aggr(values), aggregators)
☐	OPTIMIZE: write specific code for unpruned tree (essentially, skip checks at leaves)
☐	OPTIMIZE: IA3 and IA7 and relaunch comparison

☐	Note: does save_datasets error when using resumable functions?

☐	OPTIMIZE: check whether threading il actually better ( JULIA_EXCLUSIVE=1 julia -i -t30 scovid.jl -f 2>&1 | tee scan-covid-t30.out; JULIA_EXCLUSIVE=1 julia -i -t20 scovid.jl -f 2>&1 | tee scan-covid-t20.out; JULIA_EXCLUSIVE=1 julia -i -t16 scovid.jl -f 2>&1 | tee scan-covid-t16.out; JULIA_EXCLUSIVE=1 julia -i -t12 scovid.jl -f 2>&1 | tee scan-covid-t12.out; JULIA_EXCLUSIVE=1 julia -i -t8 scovid.jl -f 2>&1 | tee scan-covid-t8.out; JULIA_EXCLUSIVE=1 julia -i -t4 scovid.jl -f 2>&1 | tee scan-covid-t4.out ) &

☐	Profiling: @profile to certify the memory bottleneck

☐	tables contain a lot of redundance: perhaps use PooledArrays.jl, IndirectArrays.jl, CategoricalArrays.jl for saving space, both for saving to file AND for learing (might be beneficial for caching)?
☐	Different array implementations? Array with named dimensions? staticArrays for small domains (matrices/vectors) https://github.com/JuliaArrays/StaticArrays.jl https://github.com/davidavdav/NamedArrays.jl Etc.
☐	Functio-symbolic: tree partitions according to logical rules, but occasionally on math relations (e.g., on leaves)

☐	OPTIMIZE: Test hybrid memoization: use memoization only x% of the times
☐	Future: OPTIMIZE: Use Sys.total_memory() and Sys.free_memory() to limit load https://stackoverflow.com/questions/42599273/get-system-memory-information-from-julia#42610074


☐	Obtain best_threshold by interpolation of the loss

☐	OPTIMIZE: computation of softened operators takes too much time (optimize at least <A> in the temporal case?). Actually, this is currently not a big deal, if we don't train on InterpretedModalDataset.

☐	For temporal series, one may want to have timepoints that are scattered along the time axis. See if https://github.com/JuliaArrays/AxisArrays.jl can be of any help here; but note that one may need to know how to handle missing's
☐	Optimize RCC5
☐	Parametrize worldTypes forcing things such as MINIMUM SIZE?

☐	add parameter controlling how many thresholds are considered

☐	Maybe add new hard operator valuesbetween(a,b) (doesn't make the tree more expressive, just maybe faster at capturing patterns)
☐	Try adding ProgressMeter? https://github.com/timholy/ProgressMeter.jl

☐	Trasducers instead of iterators https://juliafolds.github.io/Transducers.jl/dev/explanation/comparison_to_iterators/#comparison-to-iterators

☐	Add point-based ontology, and test point-based + rectangle algebra?
☐	Try different optimization method: SAM https://arxiv.org/abs/2010.01412

☐	Future: ROC and pr curve in binary classification context 0/1, interpret 1-abs(class_value-score) as the confidence of the prediction; i) in Random Forest, one could aggregate tree answers in a continuous manner, and output confidence values, in this context, roc and pr curve can be computed; ii) in Decision Tree there are other approaches. Also compute ROC-AUC, and PR curve ( The Precision-Recall Plot Is More Informative than the ROC Plot When Evaluating Binary Classifiers on Imbalanced Datasets: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0118432 )

☐	Future: Feature importance with mean decreased impurity https://medium.com/the-artificial-impostor/feature-importance-measures-for-tree-models-part-i-47f187c1a2c3
☐	Future: Feature importance with one could first consider the propositional problem, the associated attributes (avg A1, max A1, min A1, std A1, avg A2, etc...), and select features using the Mutual Information Score! [https://www.kaggle.com/ryanholbrook/mutual-information]


Archive:
	✔	Add the use of an unbalanced test set, and make ConfusionMatrix compute the average recall @done (21-12-03 00:37)
	✔	Write optimized ArrayOfOnes struct for W. Someone did this already and it looks ok: https://github.com/emmt/StructuredArrays.jl . Also try: https://github.com/JuliaArrays/FillArrays.jl @done (21-10-08 00:24)
	✔	dataset-loading functions should tell about how they balanced, and how they randomized @done (21-10-07 23:35)
	✔	Parallelize tree construction? Does this require manual copy of dynamic structures used in _split! ? @done (21-10-07 23:25)
	✔	Add IA3 relations @done (21-10-07 23:24)
	✔	Refactor and distinguish between testoperators and functions; and opt/aggregator/polarity @done (21-10-07 23:19)
	✔	Add IA7 relations: Complete by writing enumAccBare, enumAcc, enumAccRepr. @done (21-10-07 23:18)
	✔	multi-frame extension! @done (21-10-07 23:16)
	✔	rename n_instances -> n_samples @done (21-10-07 23:14)
	✔	clean modallogic.jl @done (21-05-06 12:55)
	✔	timeit -> symbol @done (21-05-06 10:51)
	✔	Clean initCondition and worldType code @done (21-05-06 10:36)
	✔	check that missing is not in X or Y @done (21-05-06 10:18)
	✔	Play with parameters: @done (21-04-03 20:04)
	✔	Preliminary scan on logic-agnostic parameters @done (21-03-19 15:05)
	✔	Fix purity=-entropy and losses @done (21-03-15 14:55)
	✔	Add name of the labels to a dataset and confusion matrix. @done (21-03-15 12:14)
	✔	Create RCC5 ontology by joining n/tpp(i) into pp(i) (proper part) and dc/ec into dr (disjointness). @done (21-03-15 11:58)
	✔	Add Error catching+repeat with different log level, and keep going @done (21-03-15 11:58)
	✔	Extend to >=alpha and <alpha; these operators are ordered, closed/not closed; maybe others are categorical, in general some are. Fix </>= thing. Fix is_closed/polarity @done (21-03-15 10:55)
	✔	Fix 3 pre-pruning stop conditions: a) purity>purity_threshold; b) min_sample_{leaf,split}>=threshold{absolute,relative}; c) purity gain < min_purity_gain. What if purity is just card(max_class)/card(all classes)? Why (best_purity / nt)? If ... maybe min_purity_increase needs to become min_info_gain @done (21-03-14 23:03)
	✔	Calculate per-class accuracy. @done (21-03-12 17:10)
	✔	Create a dataset with many but tiny worlds. Even a completely random one. @done (21-03-12 14:07)
	✔	> doubles the time but doesn't seem to improve performances. Is this a bug? Try to come up with a dataset that shows if it works. If it's not a bug, maybe we should consider parametrizing on whether this is to be used or not. @done (21-03-12 14:07)
	✔	Rename TestOpLes to TestOpLeq @done (21-03-12 14:05)
	✔	Fix compute-threshold and enumAccRepr so that it works with soft test operator as well! @done (21-03-12 14:03)
	✔	Figure out why we reach "Uninformative split." when using Les only @done (21-03-10 17:21)
	✔	Test 5x5 @done (21-03-08 00:59)
	✔	Now move the extremes computation to the outer algorithm scope, so that it happens BEFORE the whole computation. @done (21-03-08 00:59)
	✔	Improve the computation of the extremes leveraging the structure of IA Frames. @done (21-03-08 00:59)
	✔	Soften > and <= to be >alpha and <=alpha. Make alpha an array to iterate over. Find an efficient way to compute it (note that with a few elements in the world, it can be made efficient with integer operations). @done (21-03-08 00:58)
	✔	enumAcc to only use channel_size and not the whole channel @done (21-03-07 16:44)
	✔	Optimize/fix topological enumerators. There may be some errors as well with interval relations (think of the TPPi thingy, that maybe happens elsewhere) @done (21-02-10 17:41)
	✔	Fix the new optimization thingy. It fails, maybe need to swap min/max. @done (21-02-05 18:06)
	✔	Parametrize on the test operators @done (21-02-02 17:52)
	✔	Test topological manually @done (21-02-02 14:57)
	✔	Fix print_world @done (21-02-02 14:07)
	✔	Check the speedup with/without inbounds (3x3 and 5x5 cases) @done (21-02-02 13:56)
	✔	verify new code. (test all datasets (avoid dataset[2] flattened)) @done (21-01-26 18:06)
	✔	Test with no initCondition @done (21-01-26 18:06)
	✔	Try different starting condition: start at the central pixel. @done (21-01-25 00:10)
	✔	Note that we need to know the speedup for using the extremes array. Hide computation of the extremes. @done (21-01-24 14:32)
	✔	Bring back the extremes, noting that this leads to constant propositional check. @done (21-01-24 14:32)
	✔	Add > @done (21-01-23 01:19)
	✔	Calculate confusion matrix @done (21-01-22 20:09)
	✔	Try the two-dimensional case! @done (21-01-21 01:12)
	✔	Use view instead of slicing @done (21-01-18 20:47)
	✔ perhaps the domain should not be 20x3x3 but 3x3x20, because Julia is column-first @done (21-01-15 14:55)
	✔	TODO const MatricialDomain{T,N} = AbstractArray{T,N} end @done (21-01-15 14:55)
